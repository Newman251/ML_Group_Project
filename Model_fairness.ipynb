{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caucasian (2103, 17)\n",
      "African-American (3175, 17)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lukej\\AppData\\Local\\Temp\\ipykernel_9512\\2353472586.py:57: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['length_of_stay'] = pd.to_datetime(df['c_jail_out']) - pd.to_datetime(df['c_jail_in'])\n",
      "C:\\Users\\lukej\\AppData\\Local\\Temp\\ipykernel_9512\\2353472586.py:58: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['length_of_stay'] = df['length_of_stay'].astype('timedelta64[D]')\n",
      "C:\\Users\\lukej\\AppData\\Local\\Temp\\ipykernel_9512\\2353472586.py:59: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['length_of_stay'] = df['length_of_stay'].astype(int)\n",
      "C:\\Users\\lukej\\AppData\\Local\\Temp\\ipykernel_9512\\2353472586.py:57: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['length_of_stay'] = pd.to_datetime(df['c_jail_out']) - pd.to_datetime(df['c_jail_in'])\n",
      "C:\\Users\\lukej\\AppData\\Local\\Temp\\ipykernel_9512\\2353472586.py:58: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['length_of_stay'] = df['length_of_stay'].astype('timedelta64[D]')\n",
      "C:\\Users\\lukej\\AppData\\Local\\Temp\\ipykernel_9512\\2353472586.py:59: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['length_of_stay'] = df['length_of_stay'].astype(int)\n",
      "C:\\Users\\lukej\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------\n",
      "------ Equlizing odds with Logistic Regression ------\n",
      "equlizing odds [0.04387190232293442, 0.5234774403842855]\n",
      "differnce in equlizing odds -0.47960553806135103\n",
      "accuracy African AMericans 0.7346437346437347\n",
      "accuracy Caucasians 0.7648456057007126\n",
      "----------------------------------------------------\n",
      "------ Equlizing odds with KNN ------\n",
      "equlizing odds [0.03330056736854814, 0.5283410533539201]\n",
      "differnce in equlizing odds -0.495040485985372\n",
      "accuracy African AMericans 0.7223587223587223\n",
      "accuracy Caucasians 0.7600950118764845\n",
      "----------------------------------------------------\n",
      "------ Equlizing odds with SVM ------\n",
      "equlizing odds [0.029765292220670148, 0.5705867215645909]\n",
      "differnce in equlizing odds -0.5408214293439207\n",
      "accuracy African AMericans 0.7223587223587223\n",
      "accuracy Caucasians 0.7648456057007126\n",
      "----------------------------------------------------\n",
      "------ Equlizing odds with MLP ------\n",
      "equlizing odds [0.07805197716729612, 0.4921598902041517]\n",
      "differnce in equlizing odds -0.41410791303685557\n",
      "accuracy African AMericans 0.7346437346437347\n",
      "accuracy Caucasians 0.7624703087885986\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#------------------------- Feature Engineering -------------------------#\n",
    "\n",
    "compas_scores_two_year= pd.read_csv(\"compas_scores_two_years.csv\",  lineterminator='\\n')\n",
    "\n",
    "# Select features from dataset\n",
    "df= compas_scores_two_year[[ 'juv_fel_count', 'juv_misd_count', 'juv_other_count' ,'age', 'c_charge_degree','race', 'score_text', 'sex', 'priors_count', 'days_b_screening_arrest', 'decile_score', 'is_recid',  'c_jail_in', 'c_jail_out',  'v_decile_score','two_year_recid\\r']]\n",
    "# Process the data\n",
    "df = df.loc[(df['days_b_screening_arrest'] <= 30) & (df['days_b_screening_arrest'] >= -30) & (df['is_recid'] != -1) & (df['c_charge_degree'] != 'O') & (df['score_text'] != 'N/A')]\n",
    "#length of stay in jail \n",
    "df['length_of_stay'] = pd.to_datetime(df['c_jail_out']) - pd.to_datetime(df['c_jail_in'])\n",
    "df['length_of_stay'] = df['length_of_stay'].astype('timedelta64[D]')\n",
    "df['length_of_stay'] = df['length_of_stay'].astype(int)\n",
    "\n",
    "#------------------------- Data Preprocessing -------------------------#\n",
    "#split into caucasian and non-caucasian\n",
    "\n",
    "df_CC = df.loc[df['race'] == 'Caucasian']\n",
    "print('Caucasian', np.shape(df_CC))\n",
    "df_AA = df.loc[df['race'] == 'African-American']\n",
    "print('African-American', np.shape(df_AA))\n",
    "\n",
    "df_NC = df.loc[df['race'] != 'Caucasian']\n",
    "\n",
    "#equalizing odds \n",
    "\n",
    "def equilizing_odds(C):\n",
    "    # #convert to probability\n",
    "    # C = (1/len(F_true_score))*C\n",
    "    # print(C)\n",
    "\n",
    "    # False postive rates :Pr[ ˆY = 1/S = 1, Y = 0] − Pr[ ˆY = 0/S = 0, Y = 0]\n",
    "    # False negative rates :Pr[ ˆY = 1/S = 1, Y = 1] − Pr[ ˆY = 0/S = 0, Y = 1]\n",
    "    \n",
    "    FNR = abs(C[0][0,1]/(C[0][0,1]+C[0][0,0]) - C[1][0,1]/(C[1][0,1]+C[1][0,0]))\n",
    "    FPR = abs(C[0][1,0]/(C[0][1,0]+C[0][1,1]) - C[1][1,0]/(C[1][1,0]+C[1][1,1]))\n",
    "\n",
    "    result = [FPR, FNR]\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "#------------------------- create factors  -------------------------#\n",
    "\n",
    "           \n",
    "\n",
    "def factoration (df_x):\n",
    "    def length_factoration (df_x):\n",
    "        df= df_x\n",
    "        #length of stay in jail \n",
    "        df['length_of_stay'] = pd.to_datetime(df['c_jail_out']) - pd.to_datetime(df['c_jail_in'])\n",
    "        df['length_of_stay'] = df['length_of_stay'].astype('timedelta64[D]')\n",
    "        df['length_of_stay'] = df['length_of_stay'].astype(int)\n",
    "\n",
    "        days = []\n",
    "        weeks = []\n",
    "        months = []\n",
    "        years = []\n",
    "\n",
    "        for length in df['length_of_stay']:\n",
    "            if length<7:\n",
    "                days.append(1)\n",
    "                weeks.append(0)\n",
    "                months.append(0)\n",
    "                years.append(0)\n",
    "            elif (length<30):\n",
    "                days.append(0)\n",
    "                weeks.append(1)\n",
    "                months.append(0)\n",
    "                years.append(0)\n",
    "            elif length<365:\n",
    "                days.append(0)\n",
    "                weeks.append(0)\n",
    "                months.append(1)\n",
    "                years.append(0)\n",
    "            else:\n",
    "                days.append(0)\n",
    "                weeks.append(0)\n",
    "                months.append(0)\n",
    "                years.append(1)\n",
    "\n",
    "        return days, weeks, months, years\n",
    "\n",
    "    def jail_factoration (df_x):\n",
    "        jail_feature = []\n",
    "        jail_feature_squared = []\n",
    "        for jail in df['length_of_stay']:\n",
    "            if(jail/365) > 1:\n",
    "                jail_feature.append(1)\n",
    "                jail_feature_squared.append((1)**2)\n",
    "            else:\n",
    "                jail_feature.append(jail/365)\n",
    "                jail_feature_squared.append((jail/365)**2)\n",
    "        return jail_feature, jail_feature_squared\n",
    "  \n",
    "    def age_factoration (df_x):\n",
    "    \n",
    "        df= df_x\n",
    "        df_age = df['age'].astype(int)\n",
    "\n",
    "        twenties_and_less = []\n",
    "        thirties=[]\n",
    "        fourties=[]\n",
    "        fifties_and_more=[]\n",
    "\n",
    "        for age in df_age:\n",
    "            if age<30:\n",
    "                twenties_and_less.append(1)\n",
    "                thirties.append(0)\n",
    "                fourties.append(0)\n",
    "                fifties_and_more.append(0)\n",
    "            elif age<40:\n",
    "                twenties_and_less.append(0)\n",
    "                thirties.append(1)\n",
    "                fourties.append(0)\n",
    "                fifties_and_more.append(0)\n",
    "            elif age<50:\n",
    "                twenties_and_less.append(0)\n",
    "                thirties.append(0)\n",
    "                fourties.append(1)\n",
    "                fifties_and_more.append(0)\n",
    "            else:\n",
    "                twenties_and_less.append(0)\n",
    "                thirties.append(0)\n",
    "                fourties.append(0)\n",
    "                fifties_and_more.append(1)\n",
    "\n",
    "        return twenties_and_less, thirties, fourties, fifties_and_more\n",
    "    \n",
    "    def age_featrure (df_x):\n",
    "        df= df_x\n",
    "        df_age = df['age'].astype(int)\n",
    "        mean_age = df_age.mean()\n",
    "        age_feature_squared = []\n",
    "        age_feature = []\n",
    "        for age in df_age:\n",
    "            if(age/mean_age) > 2:\n",
    "                age_feature.append(2)\n",
    "                age_feature_squared.append((2)**2)\n",
    "            else:\n",
    "                age_feature.append(age/mean_age)\n",
    "                age_feature_squared.append((age/mean_age)**2)\n",
    "        return age_feature, age_feature_squared\n",
    "\n",
    "    def crime_factoration (df_x):\n",
    "        df= df_x\n",
    "        df_c_charge_degree = df[['c_charge_degree']] \n",
    "        crime_factor, u_charge_degree = pd.factorize(df_c_charge_degree['c_charge_degree'])\n",
    "        return crime_factor\n",
    "\n",
    "    def gender_factoration (df_x):\n",
    "        df= df_x\n",
    "        # Gender\n",
    "        male = []\n",
    "        female = []\n",
    "        for gender in df['sex']:\n",
    "            if gender == \"Male\":\n",
    "                male.append(1)\n",
    "                female.append(0)\n",
    "            else:\n",
    "                male.append(0)\n",
    "                female.append(1)\n",
    "\n",
    "        return male, female\n",
    "    \n",
    "\n",
    "    def priors_factoration (df_x):\n",
    "        df= df_x\n",
    "        \n",
    "        # # Prior convictions\n",
    "        juvinile_felonies  = df[['juv_fel_count']].astype(int)\n",
    "        juvinile_misconduct  = df[['juv_misd_count']].astype(int)\n",
    "        juvinile_other  = df[['juv_other_count']].astype(int)\n",
    "        return juvinile_felonies, juvinile_misconduct, juvinile_other\n",
    "\n",
    "    def prior_conviction_factoration (df_x):\n",
    "        priors_count  = df['priors_count'].astype(int)\n",
    "        no_prior_convictions = []\n",
    "        one_prior =[]\n",
    "        multiple_prior = []\n",
    "        many_prior = []\n",
    "\n",
    "        # Prior Convictions Feature\n",
    "        for prior in priors_count:\n",
    "            if prior==0:\n",
    "                one_prior.append(0)\n",
    "                multiple_prior.append(0)\n",
    "                many_prior.append(0)\n",
    "                no_prior_convictions.append(1)\n",
    "            elif prior<2:\n",
    "                one_prior.append(1)\n",
    "                multiple_prior.append(0)\n",
    "                many_prior.append(0)\n",
    "                no_prior_convictions.append(0)\n",
    "            elif prior<5:\n",
    "                one_prior.append(0)\n",
    "                multiple_prior.append(1)\n",
    "                many_prior.append(0)\n",
    "                no_prior_convictions.append(0)\n",
    "            else:\n",
    "                one_prior.append(0)\n",
    "                multiple_prior.append(0)\n",
    "                many_prior.append(1)\n",
    "                no_prior_convictions.append(0)\n",
    "        return no_prior_convictions, one_prior, multiple_prior, many_prior\n",
    "\n",
    "    df= df_x\n",
    "    #length factors \n",
    "    quick_stay, short_stay, medium_stay, long_stay = length_factoration(df)\n",
    "    #age factors\n",
    "    twenties_and_less, thirties, fourties, fifties_and_more = age_factoration(df)\n",
    "    #charge factors\n",
    "    crime_factor = crime_factoration(df)\n",
    "    #gender factors\n",
    "    male, non_male = gender_factoration(df)\n",
    "    #priors factors\n",
    "    juvinile_felonies, juvinile_misconduct, juvinile_other = priors_factoration(df)\n",
    "    #prior convictions factors\n",
    "    no_prior_convictions, one_prior, multiple_prior, many_prior = prior_conviction_factoration(df)\n",
    "    #jail factors\n",
    "    jail_feature, jail_feature_squared = jail_factoration(df)\n",
    "    #age factors\n",
    "    age_feature, age_feature_squared = age_featrure(df)\n",
    "\n",
    "    X = np.column_stack((quick_stay, short_stay, medium_stay, long_stay, twenties_and_less, thirties, fourties, fifties_and_more, crime_factor, male, non_male, juvinile_felonies, juvinile_misconduct, juvinile_other, no_prior_convictions, one_prior, multiple_prior, many_prior, jail_feature, jail_feature_squared, age_feature, age_feature_squared))\n",
    "    return X\n",
    "\n",
    "\n",
    "data_CC = factoration(df_CC)\n",
    "data_AA = factoration(df_NC)\n",
    "\n",
    "# labels \n",
    "def labels(df_x):\n",
    "    df= df_x\n",
    "    f_score_text, u_score_text = pd.factorize(df['score_text'] != 'Low')\n",
    "    two_year_recid = df[['two_year_recid\\r']].astype(int)\n",
    "\n",
    "    return f_score_text, two_year_recid\n",
    "\n",
    "compas_score_CC, recid_CC = labels(df_CC)\n",
    "compas_score_AA, recid_AA = labels(df_NC)\n",
    "\n",
    "\n",
    "#------ split into train and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_CC, X_test_CC, y_train_CC, y_test_CC = train_test_split(data_CC, compas_score_CC, test_size=0.2, random_state=0)\n",
    "X_train_AA, X_test_AA, y_train_AA, y_test_AA = train_test_split(data_AA, compas_score_AA, test_size=0.2, random_state=0)\n",
    "\n",
    "X_train_CC_recide, X_test_CC_recide, y_train_CC_recide, y_test_CC_recide = train_test_split(data_CC, recid_CC, test_size=0.2, random_state=0)\n",
    "X_train_AA_recide, X_test_AA_recide, y_train_AA_recide, y_test_AA_recide = train_test_split(data_AA, recid_AA, test_size=0.2, random_state=0)\n",
    "\n",
    "# loop to increa \n",
    "\n",
    "# --------- logistic regression --------------#\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "#Logistic Regression model for CC\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train_CC, np.ravel(y_train_CC))\n",
    "y_pred_CC = logreg.predict(X_test_CC)\n",
    "\n",
    "#Logistic Regression model for AA\n",
    "#Optimal C = 1\n",
    "logreg = LogisticRegression(penalty='l2', C=10)\n",
    "logreg.fit(X_train_AA, np.ravel(y_train_AA))\n",
    "y_pred_AA = logreg.predict(X_test_AA)\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "C = confusion_matrix(y_test_AA_recide, y_pred_AA ), confusion_matrix(y_test_CC_recide, y_pred_CC )\n",
    "\n",
    "print('----------------------------------------------------')\n",
    "print('------ Equlizing odds with Logistic Regression ------')\n",
    "print('equlizing odds',equilizing_odds(C))\n",
    "print('differnce in equlizing odds',equilizing_odds(C)[0]-equilizing_odds(C)[1])\n",
    "# accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "print('accuracy African AMericans', accuracy_score(y_test_AA, y_pred_AA))\n",
    "print('accuracy Caucasians', accuracy_score(y_test_CC, y_pred_CC))\n",
    "\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "#KNN model for CC\n",
    "knn = KNeighborsClassifier(n_neighbors = 45)\n",
    "knn.fit(X_train_CC, np.ravel(y_train_CC))\n",
    "y_pred_CC = knn.predict(X_test_CC)\n",
    "\n",
    "#KNN model for AA\n",
    "knn = KNeighborsClassifier(n_neighbors = 45)\n",
    "knn.fit(X_train_AA, np.ravel(y_train_AA))\n",
    "y_pred_AA = knn.predict(X_test_AA)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "C = confusion_matrix(y_test_AA_recide, y_pred_AA ), confusion_matrix(y_test_CC_recide, y_pred_CC )\n",
    "\n",
    "print('----------------------------------------------------')\n",
    "print('------ Equlizing odds with KNN ------')\n",
    "print('equlizing odds',equilizing_odds(C))\n",
    "print('differnce in equlizing odds',equilizing_odds(C)[0]-equilizing_odds(C)[1])\n",
    "# accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "print('accuracy African AMericans', accuracy_score(y_test_AA, y_pred_AA))\n",
    "print('accuracy Caucasians', accuracy_score(y_test_CC, y_pred_CC))\n",
    "\n",
    "\n",
    "\n",
    "#------------------------- SVM model -------------------------#\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "#SVM model for CC\n",
    "svm = SVC(kernel = 'linear', C = 1)\n",
    "svm.fit(X_train_CC, np.ravel(y_train_CC))\n",
    "y_pred_CC = svm.predict(X_test_CC)\n",
    "\n",
    "#SVM model for AA\n",
    "svm = SVC(kernel = 'linear', C = 1)\n",
    "svm.fit(X_train_AA, np.ravel(y_train_AA))\n",
    "y_pred_AA = svm.predict(X_test_AA)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "C = confusion_matrix(y_test_AA_recide, y_pred_AA ), confusion_matrix(y_test_CC_recide, y_pred_CC )\n",
    "\n",
    "print('----------------------------------------------------')\n",
    "print('------ Equlizing odds with SVM ------')\n",
    "print('equlizing odds',equilizing_odds(C))\n",
    "print('differnce in equlizing odds',equilizing_odds(C)[0]-equilizing_odds(C)[1])\n",
    "# accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "print('accuracy African AMericans', accuracy_score(y_test_AA, y_pred_AA))\n",
    "print('accuracy Caucasians', accuracy_score(y_test_CC, y_pred_CC))\n",
    "\n",
    "\n",
    "#-------------------------  MLP Model  -------------------------#\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "#MLP model for CC\n",
    "model = MLPClassifier(hidden_layer_sizes=(10), max_iter=1000)\n",
    "model.fit(X_train_CC, np.ravel(y_train_CC))\n",
    "y_pred_CC = model.predict(X_test_CC)\n",
    "\n",
    "#MLP model for AA\n",
    "model = MLPClassifier(hidden_layer_sizes=(10), max_iter=1000)\n",
    "model.fit(X_train_AA, np.ravel(y_train_AA))\n",
    "y_pred_AA = model.predict(X_test_AA)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "C = confusion_matrix(y_test_AA_recide, y_pred_AA ), confusion_matrix(y_test_CC_recide, y_pred_CC )\n",
    "\n",
    "print('----------------------------------------------------')\n",
    "print('------ Equlizing odds with MLP ------')\n",
    "print('equlizing odds',equilizing_odds(C))\n",
    "print('differnce in equlizing odds',equilizing_odds(C)[0]-equilizing_odds(C)[1])\n",
    "# accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "print('accuracy African AMericans', accuracy_score(y_test_AA, y_pred_AA))\n",
    "print('accuracy Caucasians', accuracy_score(y_test_CC, y_pred_CC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of data_CC (421,)\n",
      "shape of data_CC (2103, 1)\n"
     ]
    }
   ],
   "source": [
    "print ('shape of data_CC', y_pred_CC.shape)\n",
    "print ('shape of data_CC', recid_CC.shape)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
