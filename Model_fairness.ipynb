{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caucasian (2103, 17)\n",
      "African-American (3175, 17)\n",
      "----------------------------------------------------\n",
      "------ Equlizing odds with Logistic Regression ------\n",
      "equlizing odds [0.012433821373756204, 0.5728855721393036]\n",
      "differnce in equlizing odds -0.5604517507655473\n",
      "accuracy African AMericans 0.7334152334152334\n",
      "accuracy Caucasians 0.7719714964370546\n",
      "----------------------------------------------------\n",
      "------ Equlizing odds with KNN ------\n",
      "equlizing odds [0.021625536758238917, 0.5475982158174644]\n",
      "differnce in equlizing odds -0.5259726790592254\n",
      "accuracy African AMericans 0.7211302211302212\n",
      "accuracy Caucasians 0.7624703087885986\n",
      "----------------------------------------------------\n",
      "------ Equlizing odds with SVM ------\n",
      "equlizing odds [0.041457568075603135, 0.5700205867215646]\n",
      "differnce in equlizing odds -0.5285630186459616\n",
      "accuracy African AMericans 0.7248157248157249\n",
      "accuracy Caucasians 0.7719714964370546\n",
      "----------------------------------------------------\n",
      "------ Equlizing odds with MLP ------\n",
      "equlizing odds [0.016107058478624536, 0.5763510036026762]\n",
      "differnce in equlizing odds -0.5602439451240517\n",
      "accuracy African AMericans 0.7297297297297297\n",
      "accuracy Caucasians 0.7672209026128266\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#------------------------- Feature Engineering -------------------------#\n",
    "\n",
    "compas_scores_two_year= pd.read_csv(\"compas_scores_two_years.csv\",  lineterminator='\\n')\n",
    "\n",
    "# Select features from dataset\n",
    "df= compas_scores_two_year[[ 'juv_fel_count', 'juv_misd_count', 'juv_other_count' ,'age', 'c_charge_degree','race', 'score_text', 'sex', 'priors_count', 'days_b_screening_arrest', 'decile_score', 'is_recid',  'c_jail_in', 'c_jail_out',  'v_decile_score','two_year_recid\\r']]\n",
    "# Process the data\n",
    "df = df.loc[(df['days_b_screening_arrest'] <= 30) & (df['days_b_screening_arrest'] >= -30) & (df['is_recid'] != -1) & (df['c_charge_degree'] != 'O') & (df['score_text'] != 'N/A')]\n",
    "#length of stay in jail \n",
    "df['length_of_stay'] = pd.to_datetime(df['c_jail_out']) - pd.to_datetime(df['c_jail_in'])\n",
    "df['length_of_stay'] = df['length_of_stay'].astype('timedelta64[D]')\n",
    "df['length_of_stay'] = df['length_of_stay'].astype(int)\n",
    "\n",
    "#------------------------- Data Preprocessing -------------------------#\n",
    "#split into caucasian and non-caucasian\n",
    "\n",
    "df_CC = df.loc[df['race'] == 'Caucasian']\n",
    "print('Caucasian', np.shape(df_CC))\n",
    "df_AA = df.loc[df['race'] == 'African-American']\n",
    "print('African-American', np.shape(df_AA))\n",
    "\n",
    "df_NC = df.loc[df['race'] != 'Caucasian']\n",
    "\n",
    "#equalizing odds \n",
    "\n",
    "def equilizing_odds(C):\n",
    "    # #convert to probability\n",
    "    # C = (1/len(F_true_score))*C\n",
    "    # print(C)\n",
    "\n",
    "    # False postive rates :Pr[ ˆY = 1/S = 1, Y = 0] − Pr[ ˆY = 0/S = 0, Y = 0]\n",
    "    # False negative rates :Pr[ ˆY = 1/S = 1, Y = 1] − Pr[ ˆY = 0/S = 0, Y = 1]\n",
    "    \n",
    "    FNR = abs(C[0][0,1]/(C[0][0,1]+C[0][0,0]) - C[1][0,1]/(C[1][0,1]+C[1][0,0]))\n",
    "    FPR = abs(C[0][1,0]/(C[0][1,0]+C[0][1,1]) - C[1][1,0]/(C[1][1,0]+C[1][1,1]))\n",
    "\n",
    "    result = [FPR, FNR]\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "#------------------------- create factors  -------------------------#\n",
    "\n",
    "           \n",
    "\n",
    "def factoration (df_x):\n",
    "    def length_factoration (df_x):\n",
    "        df= df_x\n",
    "        length_factor, u_length_degree = pd.factorize(df['length_of_stay'])\n",
    "\n",
    "        quick_stay = []\n",
    "        short_stay=[]\n",
    "        medium_stay=[]\n",
    "        long_stay=[]\n",
    "\n",
    "        for length in length_factor:\n",
    "            if length<5:\n",
    "                quick_stay.append(1)\n",
    "                short_stay.append(0)\n",
    "                medium_stay.append(0)\n",
    "                long_stay.append(0)\n",
    "            elif (length<15):\n",
    "                quick_stay.append(0)\n",
    "                short_stay.append(1)\n",
    "                medium_stay.append(0)\n",
    "                long_stay.append(0)\n",
    "            elif length<30:\n",
    "                quick_stay.append(0)\n",
    "                short_stay.append(0)\n",
    "                medium_stay.append(1)\n",
    "                long_stay.append(0)\n",
    "            else:\n",
    "                quick_stay.append(0)\n",
    "                short_stay.append(0)\n",
    "                medium_stay.append(0)\n",
    "                long_stay.append(1)\n",
    "\n",
    "        return quick_stay, short_stay, medium_stay, long_stay\n",
    "  \n",
    "    def age_factoration (df_x):\n",
    "    \n",
    "        df= df_x\n",
    "        df_age = df['age'].astype(int)\n",
    "\n",
    "        twenties_and_less = []\n",
    "        thirties=[]\n",
    "        fourties=[]\n",
    "        fifties_and_more=[]\n",
    "\n",
    "        for age in df_age:\n",
    "            if age<30:\n",
    "                twenties_and_less.append(1)\n",
    "                thirties.append(0)\n",
    "                fourties.append(0)\n",
    "                fifties_and_more.append(0)\n",
    "            elif age<40:\n",
    "                twenties_and_less.append(0)\n",
    "                thirties.append(1)\n",
    "                fourties.append(0)\n",
    "                fifties_and_more.append(0)\n",
    "            elif age<50:\n",
    "                twenties_and_less.append(0)\n",
    "                thirties.append(0)\n",
    "                fourties.append(1)\n",
    "                fifties_and_more.append(0)\n",
    "            else:\n",
    "                twenties_and_less.append(0)\n",
    "                thirties.append(0)\n",
    "                fourties.append(0)\n",
    "                fifties_and_more.append(1)\n",
    "\n",
    "        return twenties_and_less, thirties, fourties, fifties_and_more\n",
    "\n",
    "    def crime_factoration (df_x):\n",
    "        df= df_x\n",
    "        df_c_charge_degree = df[['c_charge_degree']] \n",
    "        crime_factor, u_charge_degree = pd.factorize(df_c_charge_degree['c_charge_degree'])\n",
    "\n",
    "\n",
    "        return crime_factor\n",
    "\n",
    "    def gender_factoration (df_x):\n",
    "        df= df_x\n",
    "        df_sex = df[['sex']]\n",
    "\n",
    "        f_gender, uniques_gender  = pd.factorize(df_sex['sex'])\n",
    "\n",
    "        return f_gender\n",
    "    \n",
    "\n",
    "    def priors_factoration (df_x):\n",
    "        df= df_x\n",
    "        \n",
    "        # # Prior convictions\n",
    "        juvinile_felonies  = df[['juv_fel_count']].astype(int)\n",
    "        juvinile_misconduct  = df[['juv_misd_count']].astype(int)\n",
    "        juvinile_other  = df[['juv_other_count']].astype(int)\n",
    "        priors_count  = df[['priors_count']].astype(int)\n",
    "\n",
    "\n",
    "\n",
    "        return juvinile_felonies, juvinile_misconduct, juvinile_other, priors_count\n",
    "\n",
    "    df= df_x\n",
    "    #length factors \n",
    "    quick_stay, short_stay, medium_stay, long_stay = length_factoration(df)\n",
    "    #age factors\n",
    "    twenties_and_less, thirties, fourties, fifties_and_more = age_factoration(df)\n",
    "    #charge factors\n",
    "    crime_factor = crime_factoration(df)\n",
    "    #gender factors\n",
    "    gender_factor = gender_factoration(df)\n",
    "    #priors factors\n",
    "    juvinile_felonies, juvinile_misconduct, juvinile_other, priors_count = priors_factoration(df)\n",
    "\n",
    "    X = np.column_stack(( crime_factor, gender_factor, priors_count, juvinile_felonies, juvinile_misconduct, juvinile_other, \n",
    "    quick_stay, short_stay, medium_stay, long_stay, twenties_and_less, thirties, fourties, fifties_and_more))\n",
    "    return X\n",
    "\n",
    "\n",
    "data_CC = factoration(df_CC)\n",
    "data_AA = factoration(df_NC)\n",
    "\n",
    "# labels \n",
    "def labels(df_x):\n",
    "    df= df_x\n",
    "    f_score_text, u_score_text = pd.factorize(df['score_text'] != 'Low')\n",
    "    two_year_recid = df[['two_year_recid\\r']].astype(int)\n",
    "\n",
    "    return f_score_text, two_year_recid\n",
    "\n",
    "compas_score_CC, recid_CC = labels(df_CC)\n",
    "compas_score_AA, recid_AA = labels(df_NC)\n",
    "\n",
    "\n",
    "#------ split into train and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_CC, X_test_CC, y_train_CC, y_test_CC = train_test_split(data_CC, compas_score_CC, test_size=0.2, random_state=0)\n",
    "X_train_AA, X_test_AA, y_train_AA, y_test_AA = train_test_split(data_AA, compas_score_AA, test_size=0.2, random_state=0)\n",
    "\n",
    "X_train_CC_recide, X_test_CC_recide, y_train_CC_recide, y_test_CC_recide = train_test_split(data_CC, recid_CC, test_size=0.2, random_state=0)\n",
    "X_train_AA_recide, X_test_AA_recide, y_train_AA_recide, y_test_AA_recide = train_test_split(data_AA, recid_AA, test_size=0.2, random_state=0)\n",
    "\n",
    "# loop to increa \n",
    "\n",
    "# --------- logistic regression --------------#\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "#Logistic Regression model for CC\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train_CC, np.ravel(y_train_CC))\n",
    "y_pred_CC = logreg.predict(X_test_CC)\n",
    "\n",
    "#Logistic Regression model for AA\n",
    "#Optimal C = 1\n",
    "logreg = LogisticRegression(penalty='l2', C=10)\n",
    "logreg.fit(X_train_AA, np.ravel(y_train_AA))\n",
    "y_pred_AA = logreg.predict(X_test_AA)\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "C = confusion_matrix(y_test_AA_recide, y_pred_AA ), confusion_matrix(y_test_CC_recide, y_pred_CC )\n",
    "\n",
    "print('----------------------------------------------------')\n",
    "print('------ Equlizing odds with Logistic Regression ------')\n",
    "print('equlizing odds',equilizing_odds(C))\n",
    "print('differnce in equlizing odds',equilizing_odds(C)[0]-equilizing_odds(C)[1])\n",
    "# accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "print('accuracy African AMericans', accuracy_score(y_test_AA, y_pred_AA))\n",
    "print('accuracy Caucasians', accuracy_score(y_test_CC, y_pred_CC))\n",
    "\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "#KNN model for CC\n",
    "knn = KNeighborsClassifier(n_neighbors = 45)\n",
    "knn.fit(X_train_CC, np.ravel(y_train_CC))\n",
    "y_pred_CC = knn.predict(X_test_CC)\n",
    "\n",
    "#KNN model for AA\n",
    "knn = KNeighborsClassifier(n_neighbors = 45)\n",
    "knn.fit(X_train_AA, np.ravel(y_train_AA))\n",
    "y_pred_AA = knn.predict(X_test_AA)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "C = confusion_matrix(y_test_AA_recide, y_pred_AA ), confusion_matrix(y_test_CC_recide, y_pred_CC )\n",
    "\n",
    "print('----------------------------------------------------')\n",
    "print('------ Equlizing odds with KNN ------')\n",
    "print('equlizing odds',equilizing_odds(C))\n",
    "print('differnce in equlizing odds',equilizing_odds(C)[0]-equilizing_odds(C)[1])\n",
    "# accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "print('accuracy African AMericans', accuracy_score(y_test_AA, y_pred_AA))\n",
    "print('accuracy Caucasians', accuracy_score(y_test_CC, y_pred_CC))\n",
    "\n",
    "\n",
    "\n",
    "#------------------------- SVM model -------------------------#\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "#SVM model for CC\n",
    "svm = SVC(kernel = 'linear', C = 1)\n",
    "svm.fit(X_train_CC, np.ravel(y_train_CC))\n",
    "y_pred_CC = svm.predict(X_test_CC)\n",
    "\n",
    "#SVM model for AA\n",
    "svm = SVC(kernel = 'linear', C = 1)\n",
    "svm.fit(X_train_AA, np.ravel(y_train_AA))\n",
    "y_pred_AA = svm.predict(X_test_AA)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "C = confusion_matrix(y_test_AA_recide, y_pred_AA ), confusion_matrix(y_test_CC_recide, y_pred_CC )\n",
    "\n",
    "print('----------------------------------------------------')\n",
    "print('------ Equlizing odds with SVM ------')\n",
    "print('equlizing odds',equilizing_odds(C))\n",
    "print('differnce in equlizing odds',equilizing_odds(C)[0]-equilizing_odds(C)[1])\n",
    "# accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "print('accuracy African AMericans', accuracy_score(y_test_AA, y_pred_AA))\n",
    "print('accuracy Caucasians', accuracy_score(y_test_CC, y_pred_CC))\n",
    "\n",
    "\n",
    "#-------------------------  MLP Model  -------------------------#\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "#MLP model for CC\n",
    "model = MLPClassifier(hidden_layer_sizes=(10), max_iter=1000)\n",
    "model.fit(X_train_CC, np.ravel(y_train_CC))\n",
    "y_pred_CC = model.predict(X_test_CC)\n",
    "\n",
    "#MLP model for AA\n",
    "model = MLPClassifier(hidden_layer_sizes=(10), max_iter=1000)\n",
    "model.fit(X_train_AA, np.ravel(y_train_AA))\n",
    "y_pred_AA = model.predict(X_test_AA)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "C = confusion_matrix(y_test_AA_recide, y_pred_AA ), confusion_matrix(y_test_CC_recide, y_pred_CC )\n",
    "\n",
    "print('----------------------------------------------------')\n",
    "print('------ Equlizing odds with MLP ------')\n",
    "print('equlizing odds',equilizing_odds(C))\n",
    "print('differnce in equlizing odds',equilizing_odds(C)[0]-equilizing_odds(C)[1])\n",
    "# accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "print('accuracy African AMericans', accuracy_score(y_test_AA, y_pred_AA))\n",
    "print('accuracy Caucasians', accuracy_score(y_test_CC, y_pred_CC))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of data_CC (421,)\n",
      "shape of data_CC (2103, 1)\n"
     ]
    }
   ],
   "source": [
    "print ('shape of data_CC', y_pred_CC.shape)\n",
    "print ('shape of data_CC', recid_CC.shape)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f844d2be2f5d9634b75a5a1c006752c2ef492e83fd3c796afe00c46304c311d6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
